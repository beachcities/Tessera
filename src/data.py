
import os
import torch
import requests
import numpy as np

# Tiny Shakespeareã®URL
DATA_URL = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'
DATA_PATH = os.path.join('data', 'input.txt')

class TextLoader:
    def __init__(self, block_size, batch_size, device='cuda'):
        self.block_size = block_size
        self.batch_size = batch_size
        self.device = device
        
        # 1. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ (ãªã‘ã‚Œã°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰)
        if not os.path.exists(DATA_PATH):
            print(f"ğŸ“¥ Downloading {DATA_URL}...")
            try:
                with open(DATA_PATH, 'w') as f:
                    f.write(requests.get(DATA_URL).text)
            except Exception as e:
                print(f"âŒ Download failed: {e}")
                raise
        
        # 2. èª­ã¿è¾¼ã¿
        with open(DATA_PATH, 'r', encoding='utf-8') as f:
            self.text = f.read()
            
        print(f"ğŸ“„ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.text)} æ–‡å­—")

        # 3. ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼æ§‹ç¯‰ (æ–‡å­—ãƒ¬ãƒ™ãƒ«)
        chars = sorted(list(set(self.text)))
        self.vocab_size = len(chars)
        self.stoi = { ch:i for i,ch in enumerate(chars) }
        self.itos = { i:ch for i,ch in enumerate(chars) }
        
        print(f"ğŸ”¡ ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªã‚µã‚¤ã‚º: {self.vocab_size} (ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ–‡å­—æ•°)")

        # 4. å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ãƒ³ã‚½ãƒ«åŒ–
        self.data = torch.tensor(self.encode(self.text), dtype=torch.long)
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿(90%) ã¨ æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿(10%) ã«åˆ†å‰²
        n = int(0.9 * len(self.data))
        self.train_data = self.data[:n]
        self.val_data = self.data[n:]

    def encode(self, s):
        return [self.stoi[c] for c in s]

    def decode(self, l):
        return ''.join([self.itos[i] for i in l])

    def get_batch(self, split):
        data = self.train_data if split == 'train' else self.val_data
        ix = torch.randint(len(data) - self.block_size, (self.batch_size,))
        x = torch.stack([data[i:i+self.block_size] for i in ix])
        y = torch.stack([data[i+1:i+self.block_size+1] for i in ix])
        
        # ãƒ‡ãƒã‚¤ã‚¹ã¸è»¢é€ (ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ã€deviceå¼•æ•°ãŒæœ‰åŠ¹ã‹ç¢ºèª)
        if self.device == 'cuda' and not torch.cuda.is_available():
            print("âš ï¸ CUDA requested but not available. Using CPU.")
            self.device = 'cpu'
            
        return x.to(self.device), y.to(self.device)

if __name__ == '__main__':
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("ğŸ§ª Testing TextLoader...")
    try:
        # ãƒ‡ãƒã‚¤ã‚¹ã¯è‡ªå‹•åˆ¤å®š
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        loader = TextLoader(block_size=8, batch_size=4, device=device)
        
        x, y = loader.get_batch('train')
        print("\n--- Batch Sample ---")
        print(f"Input shape: {x.shape}")
        print(f"Decoded Input: '{loader.decode(x[0].tolist())}'")
        print("âœ… Success! Data pipeline is ready.")
    except Exception as e:
        print(f"âŒ Error during test: {e}")
