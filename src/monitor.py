"""
TesseraMonitor - GPU Native å›²ç¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è¦³æ¸¬ç³»

è¨­è¨ˆæ€æƒ³:
- è¦³æ¸¬è‡ªä½“ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‰ãªã„
- GPUåŒæœŸã¯æœ€å°é™ï¼ˆå¿…è¦ãªã¨ãã ã‘ï¼‰
- ç•°å¸¸æ¤œçŸ¥ã¨è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆ
- Mamba SSM State ã®è¿½è·¡

Version: 0.2.2
"""

import torch
import torch.nn.functional as F
import time
import gc
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
from collections import deque


# ============================================================
# Data Classes
# ============================================================

@dataclass
class MambaStateMetrics:
    """Mamba SSM State ã®ç›£è¦–ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    ssm_state_size_mb: float = 0.0
    ssm_state_norm: float = 0.0
    ssm_state_entropy: float = 0.0
    conv_state_size_mb: float = 0.0
    ssm_state_delta_norm: float = 0.0
    ssm_state_max_activation: float = 0.0
    ssm_state_dead_units: int = 0
    ssm_state_saturated_units: int = 0


@dataclass
class FragmentationMetrics:
    """GPU ãƒ¡ãƒ¢ãƒªæ–­ç‰‡åŒ–ã®ç›£è¦–ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    allocated_mb: float = 0.0
    reserved_mb: float = 0.0
    fragmentation_ratio: float = 0.0
    num_alloc_retries: int = 0
    cached_mb: float = 0.0
    largest_free_block_mb: float = 0.0
    num_segments: int = 0


@dataclass
class Snapshot:
    """1æ™‚ç‚¹ã®å…¨è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿"""
    timestamp: float
    move_number: int
    iteration: int = 0
    
    # Memory (åŸºæœ¬)
    vram_used_mb: float = 0.0
    vram_reserved_mb: float = 0.0
    vram_max_mb: float = 0.0
    
    # Timing (ms)
    time_forward: float = 0.0
    time_legal_mask: float = 0.0
    time_play_move: float = 0.0
    time_transfer: float = 0.0
    time_ssm_step: float = 0.0
    
    # Game state
    stones_on_board: int = 0
    legal_moves_count: int = 0
    context_length: int = 0
    
    # Learning
    loss: float = 0.0
    gradient_norm: float = 0.0
    
    # Mamba State
    mamba: Optional[MambaStateMetrics] = None
    
    # Fragmentation
    fragmentation: Optional[FragmentationMetrics] = None


# ============================================================
# Main Monitor Class
# ============================================================

class TesseraMonitor:
    """
    Tessera/MambaGo è¦³æ¸¬ç³»
    
    æœ€é‡è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ Top 5:
    1. time_transfer - CPU-GPUè»¢é€æ™‚é–“ï¼ˆ0ã§ã‚ã‚‹ã¹ãï¼‰
    2. vram_used_mb - VRAMä½¿ç”¨é‡
    3. fragmentation_ratio - ãƒ¡ãƒ¢ãƒªæ–­ç‰‡åŒ–
    4. ssm_state_norm - SSMçŠ¶æ…‹ã®ç™ºæ•£æ¤œçŸ¥
    5. move_number + legal_moves_count - ã‚²ãƒ¼ãƒ é€²è¡Œã®å¥å…¨æ€§
    
    æ¨å¥¨ãƒ­ã‚°é »åº¦:
    - time_forward, time_legal_mask, time_transfer: æ¯æ‰‹
    - ssm_state_norm, ssm_state_delta_norm: 10æ‰‹ã”ã¨
    - fragmentation_ratio, vram_used_mb: 50æ‰‹ã”ã¨
    - å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è©³ç´°ã‚µãƒãƒªãƒ¼: 100æ‰‹ã”ã¨
    """
    
    def __init__(self,
                 history_size: int = 1000,
                 alert_vram_threshold: float = 0.85,
                 alert_fragmentation_threshold: float = 1.5,
                 alert_state_norm_threshold: float = 100.0,
                 alert_transfer_threshold: float = 1.0):
        
        self.history: deque[Snapshot] = deque(maxlen=history_size)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤
        self.alert_vram_threshold = alert_vram_threshold
        self.alert_fragmentation_threshold = alert_fragmentation_threshold
        self.alert_state_norm_threshold = alert_state_norm_threshold
        self.alert_transfer_threshold = alert_transfer_threshold
        
        # ã‚¿ã‚¤ãƒãƒ¼
        self._timers: Dict[str, float] = {}
        self._current_snapshot: Dict[str, Any] = {}
        
        # å‰å›ã®Mamba Stateï¼ˆå·®åˆ†è¨ˆç®—ç”¨ï¼‰
        self._prev_ssm_state: Optional[torch.Tensor] = None
        
        # çµ±è¨ˆ
        self._alert_count = 0

    # ============================================================
    # Memory Tracking
    # ============================================================
    
    def snapshot_vram(self) -> Dict[str, float]:
        """åŸºæœ¬çš„ãªVRAMæƒ…å ±ã‚’å–å¾—"""
        if not torch.cuda.is_available():
            return {'used_mb': 0, 'reserved_mb': 0, 'max_mb': 0}
        
        return {
            'used_mb': torch.cuda.memory_allocated() / 1024**2,
            'reserved_mb': torch.cuda.memory_reserved() / 1024**2,
            'max_mb': torch.cuda.get_device_properties(0).total_memory / 1024**2,
        }
    
    def snapshot_fragmentation(self) -> FragmentationMetrics:
        """ãƒ¡ãƒ¢ãƒªæ–­ç‰‡åŒ–ã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        if not torch.cuda.is_available():
            return FragmentationMetrics()
        
        allocated = torch.cuda.memory_allocated() / 1024**2
        reserved = torch.cuda.memory_reserved() / 1024**2
        
        # æ–­ç‰‡åŒ–ç‡: reserved ãŒ allocated ã‚ˆã‚Šå¤§ãã„ã»ã©æ–­ç‰‡åŒ–
        frag_ratio = reserved / allocated if allocated > 0 else 1.0
        
        # ãƒ¡ãƒ¢ãƒªçµ±è¨ˆã‚’å–å¾—
        try:
            stats = torch.cuda.memory_stats()
            num_alloc_retries = stats.get('num_alloc_retries', 0)
            num_segments = stats.get('num_segments', 0)
        except:
            num_alloc_retries = 0
            num_segments = 0
        
        return FragmentationMetrics(
            allocated_mb=allocated,
            reserved_mb=reserved,
            fragmentation_ratio=frag_ratio,
            num_alloc_retries=num_alloc_retries,
            num_segments=num_segments,
            largest_free_block_mb=reserved - allocated,
        )

    # ============================================================
    # Mamba State Tracking
    # ============================================================
    
    def snapshot_mamba_state(self,
                             ssm_state: Optional[torch.Tensor],
                             conv_state: Optional[torch.Tensor] = None) -> MambaStateMetrics:
        """
        Mamba ã® SSM State ã‚’åˆ†æ
        
        Args:
            ssm_state: shape (batch, d_model, d_state) or similar
            conv_state: shape (batch, d_model, d_conv)
        """
        metrics = MambaStateMetrics()
        
        if ssm_state is None:
            return metrics
        
        with torch.no_grad():
            # ã‚µã‚¤ã‚º
            metrics.ssm_state_size_mb = ssm_state.element_size() * ssm_state.numel() / 1024**2
            
            # ãƒãƒ«ãƒ ï¼ˆç™ºæ•£æ¤œçŸ¥ï¼‰
            metrics.ssm_state_norm = ssm_state.norm().item()
            
            # æœ€å¤§æ´»æ€§å€¤ï¼ˆé£½å’Œæ¤œçŸ¥ï¼‰
            metrics.ssm_state_max_activation = ssm_state.abs().max().item()
            
            # Dead unitsï¼ˆæ´»æ€§ãŒã»ã¼ã‚¼ãƒ­ï¼‰
            flat = ssm_state.view(-1)
            metrics.ssm_state_dead_units = (flat.abs() < 1e-6).sum().item()
            
            # Saturated unitsï¼ˆä¸Šé™ã«å¼µã‚Šä»˜ãï¼‰
            metrics.ssm_state_saturated_units = (flat.abs() > 10.0).sum().item()
            
            # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼ˆæƒ…å ±é‡ã®æŒ‡æ¨™ï¼‰
            try:
                probs = F.softmax(ssm_state.view(-1).float(), dim=0)
                metrics.ssm_state_entropy = -(probs * (probs + 1e-10).log()).sum().item()
            except:
                metrics.ssm_state_entropy = 0.0
            
            # å‰ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ã®å¤‰åŒ–é‡
            if self._prev_ssm_state is not None:
                try:
                    if self._prev_ssm_state.shape == ssm_state.shape:
                        delta = ssm_state - self._prev_ssm_state
                        metrics.ssm_state_delta_norm = delta.norm().item()
                except:
                    pass
            
            # ç¾åœ¨ã®çŠ¶æ…‹ã‚’ä¿å­˜
            self._prev_ssm_state = ssm_state.detach().clone()
        
        if conv_state is not None:
            metrics.conv_state_size_mb = conv_state.element_size() * conv_state.numel() / 1024**2
        
        return metrics

    # ============================================================
    # Timing
    # ============================================================
    
    def start_timer(self, name: str):
        """è¨ˆæ¸¬é–‹å§‹ï¼ˆGPUåŒæœŸã‚ã‚Šï¼‰"""
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        self._timers[name] = time.perf_counter()
    
    def stop_timer(self, name: str) -> float:
        """è¨ˆæ¸¬çµ‚äº†ã€ms ã§è¿”ã™"""
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        elapsed = (time.perf_counter() - self._timers.get(name, time.perf_counter())) * 1000
        self._current_snapshot[f'time_{name}'] = elapsed
        return elapsed
    
    class _TimerContext:
        """ã‚¿ã‚¤ãƒãƒ¼ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
        def __init__(self, monitor: 'TesseraMonitor', name: str):
            self.monitor = monitor
            self.name = name
        
        def __enter__(self):
            self.monitor.start_timer(self.name)
            return self
        
        def __exit__(self, *args):
            self.monitor.stop_timer(self.name)
    
    def time(self, name: str) -> _TimerContext:
        """
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã‚¿ã‚¤ãƒŸãƒ³ã‚°è¨ˆæ¸¬
        
        Usage:
            with monitor.time('forward'):
                output = model(input)
        """
        return self._TimerContext(self, name)

    # ============================================================
    # Recording
    # ============================================================
    
    def record(self,
               move_number: int,
               iteration: int = 0,
               ssm_state: Optional[torch.Tensor] = None,
               conv_state: Optional[torch.Tensor] = None,
               **kwargs) -> Snapshot:
        """
        ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’è¨˜éŒ²
        
        Args:
            move_number: ç¾åœ¨ã®æ‰‹æ•°
            iteration: å­¦ç¿’ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            ssm_state: Mamba ã® SSM Stateï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            conv_state: Mamba ã® Conv Stateï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            **kwargs: è¿½åŠ ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆstones_on_board, legal_moves_count ç­‰ï¼‰
        """
        vram = self.snapshot_vram()
        frag = self.snapshot_fragmentation()
        mamba = self.snapshot_mamba_state(ssm_state, conv_state)
        
        # ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
        timing_data = {k: v for k, v in self._current_snapshot.items() if k.startswith('time_')}
        
        snapshot = Snapshot(
            timestamp=time.time(),
            move_number=move_number,
            iteration=iteration,
            vram_used_mb=vram.get('used_mb', 0),
            vram_reserved_mb=vram.get('reserved_mb', 0),
            vram_max_mb=vram.get('max_mb', 0),
            mamba=mamba,
            fragmentation=frag,
            **timing_data,
            **kwargs
        )
        
        self.history.append(snapshot)
        self._check_alerts(snapshot)
        self._current_snapshot = {}
        
        return snapshot

    # ============================================================
    # Alerts
    # ============================================================
    
    def _check_alerts(self, s: Snapshot):
        """ç•°å¸¸æ¤œçŸ¥ã¨ã‚¢ãƒ©ãƒ¼ãƒˆç™ºå ±"""
        alerts = []
        
        # 1. CPU-GPUè»¢é€ï¼ˆæœ€é‡è¦ï¼‰
        if s.time_transfer > self.alert_transfer_threshold:
            alerts.append(f"ğŸ”´ TRANSFER {s.time_transfer:.1f}ms")
        
        # 2. VRAMä½¿ç”¨ç‡
        if s.vram_max_mb > 0:
            vram_ratio = s.vram_used_mb / s.vram_max_mb
            if vram_ratio > self.alert_vram_threshold:
                alerts.append(f"ğŸ”´ VRAM {vram_ratio*100:.1f}%")
        
        # 3. æ–­ç‰‡åŒ–
        if s.fragmentation and s.fragmentation.fragmentation_ratio > self.alert_fragmentation_threshold:
            alerts.append(f"ğŸŸ¡ FRAG {s.fragmentation.fragmentation_ratio:.2f}x")
        
        # 4. SSM State ç™ºæ•£
        if s.mamba and s.mamba.ssm_state_norm > self.alert_state_norm_threshold:
            alerts.append(f"ğŸ”´ SSM_NORM {s.mamba.ssm_state_norm:.1f}")
        
        # 5. SSM State åœæ»
        if s.mamba and s.move_number > 10 and s.mamba.ssm_state_delta_norm < 1e-6:
            alerts.append("ğŸŸ¡ SSM_STAGNANT")
        
        # 6. Dead units ãŒå¤šã„
        if s.mamba and s.mamba.ssm_state_dead_units > 100:
            alerts.append(f"ğŸŸ¡ DEAD_UNITS {s.mamba.ssm_state_dead_units}")
        
        if alerts:
            self._alert_count += len(alerts)
            print(f"âš ï¸ Move {s.move_number}: {', '.join(alerts)}")

    # ============================================================
    # Analysis
    # ============================================================
    
    def memory_trend(self) -> Dict[str, List[tuple]]:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¨ç§»"""
        return {
            'vram': [(s.move_number, s.vram_used_mb) for s in self.history],
            'ssm_state': [(s.move_number, s.mamba.ssm_state_size_mb) 
                         for s in self.history if s.mamba],
            'fragmentation': [(s.move_number, s.fragmentation.fragmentation_ratio)
                             for s in self.history if s.fragmentation],
        }
    
    def mamba_state_trend(self) -> Dict[str, List[tuple]]:
        """Mamba State ã®æ¨ç§»"""
        return {
            'norm': [(s.move_number, s.mamba.ssm_state_norm) 
                    for s in self.history if s.mamba],
            'entropy': [(s.move_number, s.mamba.ssm_state_entropy)
                       for s in self.history if s.mamba],
            'delta': [(s.move_number, s.mamba.ssm_state_delta_norm)
                     for s in self.history if s.mamba],
            'dead_units': [(s.move_number, s.mamba.ssm_state_dead_units)
                          for s in self.history if s.mamba],
        }
    
    def find_anomalies(self) -> Dict[str, List[Snapshot]]:
        """å„ç¨®ç•°å¸¸ã‚’æ¤œå‡º"""
        anomalies = {
            'memory_spike': [],
            'fragmentation_spike': [],
            'state_divergence': [],
            'state_stagnation': [],
        }
        
        prev = None
        for s in self.history:
            if prev:
                # ãƒ¡ãƒ¢ãƒªã‚¹ãƒ‘ã‚¤ã‚¯ï¼ˆ50MBä»¥ä¸Šã®æ€¥å¢—ï¼‰
                if s.vram_used_mb - prev.vram_used_mb > 50:
                    anomalies['memory_spike'].append(s)
                
                # æ–­ç‰‡åŒ–ã‚¹ãƒ‘ã‚¤ã‚¯
                if (s.fragmentation and prev.fragmentation and
                    s.fragmentation.fragmentation_ratio - prev.fragmentation.fragmentation_ratio > 0.2):
                    anomalies['fragmentation_spike'].append(s)
                
                # Stateç™ºæ•£
                if (s.mamba and prev.mamba and
                    s.mamba.ssm_state_norm > prev.mamba.ssm_state_norm * 1.5):
                    anomalies['state_divergence'].append(s)
                
                # Stateåœæ»
                if s.mamba and s.mamba.ssm_state_delta_norm < 1e-6 and s.move_number > 10:
                    anomalies['state_stagnation'].append(s)
            
            prev = s
        
        return anomalies

    # ============================================================
    # Output
    # ============================================================
    
    def print_summary(self):
        """è©³ç´°ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ“Š Tessera Monitor Summary")
        print("="*60)
        
        if not self.history:
            print("No data recorded yet.")
            return
        
        latest = self.history[-1]
        
        # åŸºæœ¬æƒ…å ±
        print(f"\nğŸ® Game State:")
        print(f"   Move: {latest.move_number}, Iteration: {latest.iteration}")
        print(f"   Stones: {latest.stones_on_board}, Legal moves: {latest.legal_moves_count}")
        
        # ãƒ¡ãƒ¢ãƒª
        print(f"\nğŸ’¾ Memory:")
        vram_pct = latest.vram_used_mb / latest.vram_max_mb * 100 if latest.vram_max_mb > 0 else 0
        print(f"   VRAM: {latest.vram_used_mb:.1f} / {latest.vram_max_mb:.1f} MB ({vram_pct:.1f}%)")
        if latest.fragmentation:
            f = latest.fragmentation
            print(f"   Fragmentation: {f.fragmentation_ratio:.2f}x (segments: {f.num_segments})")
        
        # Mamba State
        if latest.mamba:
            m = latest.mamba
            print(f"\nğŸ Mamba SSM State:")
            print(f"   Size: {m.ssm_state_size_mb:.2f} MB")
            print(f"   Norm: {m.ssm_state_norm:.2f}")
            print(f"   Entropy: {m.ssm_state_entropy:.2f}")
            print(f"   Delta: {m.ssm_state_delta_norm:.4f}")
            print(f"   Dead/Saturated: {m.ssm_state_dead_units}/{m.ssm_state_saturated_units}")
        
        # ã‚¿ã‚¤ãƒŸãƒ³ã‚°
        timing_attrs = ['time_forward', 'time_legal_mask', 'time_play_move', 'time_transfer']
        timing_values = [(attr, getattr(latest, attr, 0)) for attr in timing_attrs if getattr(latest, attr, 0) > 0]
        if timing_values:
            print(f"\nâ±ï¸ Timing (latest):")
            for name, val in timing_values:
                print(f"   {name}: {val:.2f} ms")
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        if len(self.history) > 10:
            print(f"\nğŸ“ˆ Trends (first 10 â†’ last 10):")
            
            early = list(self.history)[:10]
            late = list(self.history)[-10:]
            
            early_vram = sum(s.vram_used_mb for s in early) / 10
            late_vram = sum(s.vram_used_mb for s in late) / 10
            print(f"   VRAM: {early_vram:.1f} â†’ {late_vram:.1f} MB ({late_vram-early_vram:+.1f})")
            
            early_mamba = [s for s in early if s.mamba]
            late_mamba = [s for s in late if s.mamba]
            if early_mamba and late_mamba:
                early_norm = sum(s.mamba.ssm_state_norm for s in early_mamba) / len(early_mamba)
                late_norm = sum(s.mamba.ssm_state_norm for s in late_mamba) / len(late_mamba)
                print(f"   SSM Norm: {early_norm:.2f} â†’ {late_norm:.2f} ({late_norm-early_norm:+.2f})")
        
        # ç•°å¸¸ã‚µãƒãƒªãƒ¼
        anomalies = self.find_anomalies()
        total_anomalies = sum(len(v) for v in anomalies.values())
        print(f"\nâš ï¸ Alerts: {self._alert_count} total")
        if total_anomalies > 0:
            print(f"   Anomalies detected: {total_anomalies}")
            for name, items in anomalies.items():
                if items:
                    moves = [s.move_number for s in items[:5]]
                    suffix = '...' if len(items) > 5 else ''
                    print(f"   - {name}: moves {moves}{suffix}")
        
        print("\n" + "="*60)
    
    def get_top5_metrics(self) -> Dict[str, Any]:
        """æœ€é‡è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ Top 5 ã‚’å–å¾—"""
        if not self.history:
            return {}
        
        latest = self.history[-1]
        return {
            'time_transfer': latest.time_transfer,
            'vram_used_mb': latest.vram_used_mb,
            'fragmentation_ratio': latest.fragmentation.fragmentation_ratio if latest.fragmentation else 0,
            'ssm_state_norm': latest.mamba.ssm_state_norm if latest.mamba else 0,
            'legal_moves_count': latest.legal_moves_count,
        }


# ============================================================
# Utility Functions
# ============================================================

def defragment_gpu_memory():
    """
    GPUãƒ¡ãƒ¢ãƒªã®æ–­ç‰‡åŒ–ã‚’è»½æ¸›
    å­¦ç¿’ã®åˆé–“ï¼ˆä¾‹: 100æ‰‹ã”ã¨ï¼‰ã«å‘¼ã¶
    """
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()
        torch.cuda.synchronize()


# ============================================================
# Mamba State Capture Hook
# ============================================================

class MambaStateCapture:
    """
    MambaBlock.forward ã« hook ã‚’æŒ¿å…¥ã—ã€SSM State ã‚’å–å¾—ã™ã‚‹
    
    Usage:
        capture = MambaStateCapture(model)
        output = model(input)
        state = capture.get_state()
    """
    
    def __init__(self, model):
        self.captured_state = None
        self._hook_handle = None
        
        # Mamba ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ¢ã—ã¦ãƒ•ãƒƒã‚¯ã‚’ç™»éŒ²
        self._register_hook(model)
    
    def _register_hook(self, model):
        """Mambaãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ãƒ•ãƒƒã‚¯ã‚’ç™»éŒ²"""
        def hook_fn(module, input, output):
            # mamba-ssm ã®å®Ÿè£…ã«ã‚ˆã‚Šç•°ãªã‚‹
            # æ–¹æ³•1: last_state å±æ€§
            if hasattr(module, 'last_state'):
                self.captured_state = module.last_state.detach().clone()
            # æ–¹æ³•2: å‡ºåŠ›ãŒã‚¿ãƒ—ãƒ«ã®å ´åˆ
            elif isinstance(output, tuple) and len(output) > 1:
                self.captured_state = output[1].detach().clone() if output[1] is not None else None
        
        # Mamba ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’æ¢ã™
        for name, module in model.named_modules():
            if 'mamba' in name.lower() or module.__class__.__name__ == 'Mamba':
                self._hook_handle = module.register_forward_hook(hook_fn)
                break
    
    def get_state(self) -> Optional[torch.Tensor]:
        """ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ãŸçŠ¶æ…‹ã‚’å–å¾—"""
        return self.captured_state
    
    def remove_hook(self):
        """ãƒ•ãƒƒã‚¯ã‚’è§£é™¤"""
        if self._hook_handle:
            self._hook_handle.remove()


# ============================================================
# Test
# ============================================================

if __name__ == "__main__":
    print("Testing TesseraMonitor...")
    
    # ãƒ¢ãƒ‹ã‚¿ãƒ¼åˆæœŸåŒ–
    monitor = TesseraMonitor()
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§è¨˜éŒ²ãƒ†ã‚¹ãƒˆ
    for move in range(20):
        with monitor.time('forward'):
            time.sleep(0.001)  # 1ms ã®ãƒ€ãƒŸãƒ¼å‡¦ç†
        
        with monitor.time('legal_mask'):
            time.sleep(0.0005)
        
        # ãƒ€ãƒŸãƒ¼ã® SSM State
        if torch.cuda.is_available():
            dummy_state = torch.randn(4, 256, 16, device='cuda')
        else:
            dummy_state = torch.randn(4, 256, 16)
        
        monitor.record(
            move_number=move,
            ssm_state=dummy_state,
            stones_on_board=move * 2,
            legal_moves_count=361 - move * 2,
        )
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    monitor.print_summary()
    
    # Top 5 ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    print("\nTop 5 Metrics:")
    print(monitor.get_top5_metrics())
    
    print("\nâœ… TesseraMonitor test passed!")
