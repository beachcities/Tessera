import torch
from mamba_ssm import Mamba

# 1. GPUãŒä½¿ãˆã‚‹ã‹ç¢ºèª
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸš€ Device: {device}")

try:
    # 2. Mambaãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ï¼ˆå‹•ä½œç¢ºèªç”¨ã®è¶…å°å‹ç‰ˆï¼‰
    model = Mamba(
        d_model=64,   # ãƒ¢ãƒ‡ãƒ«ã®å¤ªã•
        d_state=16,   # è¨˜æ†¶ã®å®¹é‡
        d_conv=4,     # ç•³ã¿è¾¼ã¿å¹…
        expand=2      # æ‹¡å¼µä¿‚æ•°
    ).to(device)

    # 3. ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ (ãƒãƒƒãƒã‚µã‚¤ã‚º:2, é•·ã•:128, æ¬¡å…ƒ:64)
    x = torch.randn(2, 128, 64).to(device)

    # 4. æ¨è«–å®Ÿè¡Œï¼ˆé †ä¼æ’­ï¼‰
    y = model(x)

    print(f"âœ… Input shape: {x.shape}")
    print(f"âœ… Output shape: {y.shape}")
    print("ğŸ‰ Success! Mamba is running on your RTX 4070.")

except Exception as e:
    print(f"âŒ Error: {e}")