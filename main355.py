import os
import time
import sys
import torch
import torch.nn as nn
import ray
from mamba_ssm import Mamba

# ---------------------------------------------------------
# 1. è¨­å®š (Configuration)
# ---------------------------------------------------------
VOCAB_SIZE = 100
D_MODEL = 256
D_STATE = 16
D_CONV = 4
EXPAND = 2
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# â˜… ã„ã‚ˆã„ã‚ˆæœ¬ç•ªæ§‹æˆï¼š8ä¸¦åˆ— â˜…
NUM_ACTORS = 8     
BATCH_SIZE = 4
SEQ_LEN = 32

# ---------------------------------------------------------
# 2. ãƒ¢ãƒ‡ãƒ«å®šç¾©
# ---------------------------------------------------------
class MambaModel(nn.Module):
    def __init__(self, vocab_size, d_model, d_state, d_conv, expand):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, d_model)
        self.mamba = Mamba(
            d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand
        )
        self.head = nn.Linear(d_model, vocab_size)

    def forward(self, x):
        x = self.embedding(x)
        x = self.mamba(x)
        return self.head(x)

# ---------------------------------------------------------
# 3. Ray Actorå®šç¾© (Warm-up & Inference Modeæ­è¼‰)
# ---------------------------------------------------------
@ray.remote(num_gpus=0.1)
class SelfPlayActorV3:
    def __init__(self, actor_id):
        self.actor_id = actor_id
        self.device = DEVICE
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.model = MambaModel(VOCAB_SIZE, D_MODEL, D_STATE, D_CONV, EXPAND).to(self.device)
        self.criterion = nn.CrossEntropyLoss()
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        self.dummy_input = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, SEQ_LEN)).to(self.device)
        self.dummy_target = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, SEQ_LEN)).to(self.device)

        # â˜… Warm-up: åˆå›ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚’ã“ã“ã§æ¸ˆã¾ã›ã‚‹
        print(f"(Actor {actor_id}) ğŸ”¨ Warming up (Compiling Mamba)...")
        self._run_forward_pass() 
        print(f"(Actor {actor_id}) âœ… Ready (Warm-up complete).")

    def _run_forward_pass(self):
        # å…±é€šå‡¦ç†ã¨ã—ã¦åˆ‡ã‚Šå‡ºã—
        # ä»Šå›ã¯å­¦ç¿’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã ãŒã€ãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚å‹¾é…è¨ˆç®—ãªã—ãƒ¢ãƒ¼ãƒ‰ã§å‹•ã‹ã™
        with torch.inference_mode():
            logits = self.model(self.dummy_input)
            # â˜… å®‰å…¨ãª reshape ã«å¤‰æ›´
            logits_flat = logits.reshape(-1, VOCAB_SIZE)
            target_flat = self.dummy_target.view(-1)
            loss = self.criterion(logits_flat, target_flat)
        return loss.item()

    def train_step(self):
        # æœ¬ç•ªãƒ«ãƒ¼ãƒ—ã§ã¯ã“ã‚Œã‚’å‘¼ã¶ã ã‘ï¼ˆã™ã§ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã§é«˜é€Ÿï¼‰
        loss_val = self._run_forward_pass()
        return {"loss": loss_val, "id": self.actor_id}

# ---------------------------------------------------------
# 4. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ«ãƒ¼ãƒ—
# ---------------------------------------------------------
def start_training():
    print(f"ğŸš€ Main: Starting program ({NUM_ACTORS} Actors Mode) on {DEVICE}...")

    if ray.is_initialized():
        ray.shutdown()
    ray.init(ignore_reinit_error=True, log_to_driver=False)

    print(f"ğŸ‘¥ DEBUG: Spawning {NUM_ACTORS} GPU Actors (This will take time for Warm-up)...")
    
    # ã“ã“ã§å„Actorã® __init__ ãŒèµ°ã‚Šã€ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¾…ã¡ãŒç™ºç”Ÿã™ã‚‹
    # ã—ã‹ã—ã€ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã«å…¥ã‚‹å‰ã«çµ‚ã‚ã‚‹ã®ã§ UX ãŒè‰¯ã„
    actors = [SelfPlayActorV3.remote(i) for i in range(NUM_ACTORS)]
    
    # å…¨å“¡ãŒ Ready ã«ãªã‚‹ã¾ã§å¾…ã¤æ‰‹ã‚‚ã‚ã‚‹ãŒã€Rayã¯é…å»¶å®Ÿè¡Œã—ã¦ãã‚Œã‚‹ã®ã§ãã®ã¾ã¾é€²ã‚€
    print("âœ… DEBUG: Actors spawned. Starting loop...")
    print("-" * 60)

    try:
        for step in range(1, 1001):
            
            # --- ä¸¦åˆ—å®Ÿè¡Œ ---
            futures = [actor.train_step.remote() for actor in actors]
            
            start_wait = time.time()
            pending = futures
            
            # Warm-upæ¸ˆã¿ãªã®ã§ã€Step1ã‹ã‚‰é«˜é€Ÿãªã¯ãšï¼
            guideline_limit = 30 # ã‚‚ã†300ç§’ã‚‚å¾…ã¤å¿…è¦ã¯ãªã„
            
            while len(pending) > 0:
                finished, pending = ray.wait(pending, timeout=0.5)
                
                if len(pending) > 0:
                    elapsed = int(time.time() - start_wait)
                    status = "âš¡ Calculating"

                    if elapsed > guideline_limit:
                        advice = f"âš ï¸ Too Long! (> {guideline_limit}s). Consider Stop."
                    else:
                        advice = f"(Limit: ~{guideline_limit}s)"

                    spinner = ["|", "/", "-", "\\"][elapsed % 4]
                    sys.stdout.write(f"\r{spinner} {status} | Time: {elapsed}s {advice} | Waiting: {len(pending)} ")
                    sys.stdout.flush()
            
            # --- å®Œäº† ---
            results = ray.get(futures)
            total_loss = sum(r['loss'] for r in results) / len(results)
            
            # å®Œäº†ãƒ­ã‚° (VRAMç¯€ç´„ãƒ¢ãƒ¼ãƒ‰ãªã®ã§çˆ†é€Ÿã®ã¯ãš)
            print(f"\râœ… Step {step:04d} | Loss: {total_loss:.4f} | Time: {int(time.time()-start_wait)}s {' '*30}")

    except KeyboardInterrupt:
        print("\n\nğŸ›‘ STOP: User stopped training.")
    except Exception as e:
        print(f"\nâŒ ERROR: {e}")
    finally:
        ray.shutdown()

if __name__ == "__main__":
    start_training()