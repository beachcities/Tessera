# Tessera Known Traps

Tesseraプロジェクトで発見された技術的な罠（失敗パターン）を記録する。
将来の開発者（人間・AI）が同じ失敗を繰り返さないための知見集。

---

## TRAP-001: パス連打ハック（Pass Spamming Hack）

**発見日:** 2026-01-18
**深刻度:** 🔴 Critical
**状態:** 🔄 対処中

### 症状

- Loss が急激に改善（5.9 → 3.58）
- しかし Win Rate は 0%
- 対局を観察すると、パスを連打してゲームが即終了

### 原因

1. **パス制限なし**: 序盤からパスが可能
2. **終局即報酬**: パス連打で即座に勝敗が決まり、報酬を得られる
3. **サンプリング偏り**: 終局直前のサンプルに偏り、盤面中盤を学習しない

### なぜ危険か

- Loss という指標が「学習成功」を示さない
- 見かけ上の「相転移」が実は「ハックの学習」
- 長時間学習後に発覚すると、時間が無駄になる

### 対策

| 対策 | 説明 |
|------|------|
| **パス制限** | N手（例: 50手）まではパス禁止 |
| **8点サンプリング** | ゲーム全体から均等にサンプル |
| **パスペナルティ** | パス選択に対するペナルティ |
| **定期的なWin Rate確認** | Loss だけでなく eval_quick.py で挙動確認 |

### 教訓

> **「Loss の低下を無批判に喜ばない」**

Loss が改善しても、実際の性能（Win Rate）が伴わなければ意味がない。

---

## TRAP-002: vocab_size の次元混乱

**発見日:** 2026-01-19
**深刻度:** 🟡 Medium
**状態:** ✅ 解決

### 症状

- 文書によって vocab_size の記載が異なる（362, 363, 364）
- 実装と文書の乖離
- 新規参加者が混乱

### 原因

1. **設計変更の未反映**: EOS_TOKEN を廃止したが文書が古いまま
2. **複数の「次元」**: Embedding次元とPolicyHead出力次元が異なる
3. **コミット漏れ**: ローカル変更がGitHubに反映されていない

### 正しい理解

| 数値 | 意味 | 用途 |
|------|------|------|
| 361 | 盤上座標（19×19） | - |
| 362 | 盤上 + PASS | PolicyHead出力（着手可能空間） |
| 363 | 盤上 + PASS + PAD | vocab_size（Embedding次元） |
| 364 | 旧仕様（EOS含む） | **廃止** |

### 対策

1. **トークン設計セクションを全文書に追加**
2. **両方の次元を明記**（vocab_size と PolicyHead出力）
3. **Git同期の徹底**

### 教訓

> **「実装と文書を同時に更新する」**

---

## TRAP-003: MambaStateCapture によるメモリリーク

**発見日:** 2026-01-14（Phase II）
**深刻度:** 🔴 Critical
**状態:** ✅ 解決

### 症状

- ELO評価時にOOM（Out of Memory）が頻発
- 長時間学習で徐々にメモリ使用量が増加

### 原因

- forward hook が hidden state を保持し続けた
- ガベージコレクションが効かない

### 対策

**MambaStateCapture クラスを完全削除**

### 結果

790回のELO評価でOOMゼロ

### 教訓

> **「forward hook は危険。使う場合は必ずメモリ管理を確認」**

---

## TRAP-004: Pythonループによる速度低下

**発見日:** 2026-01-16（Phase III.1）
**深刻度:** 🟡 Medium
**状態:** ✅ 解決

### 症状

- 学習速度が 3.1 g/s で頭打ち
- GPU使用率が低い

### 原因

- 連検出・捕獲処理がPythonループで実装されていた
- CPUとGPU間の同期待ちが発生

### 対策

1. **Tromp-Taylor採用**: 捕獲ロジック自体を廃止
2. **全操作をテンソル演算に**: No Python Loop

### 結果

学習速度 3.1 → 15.6 g/s（5倍向上）

### 教訓

> **「GPU sovereignty を守れ。Pythonループは敵」**

---

## TRAP-005: 文書間の整合性崩壊

**発見日:** 2026-01-19
**深刻度:** 🟡 Medium
**状態:** ✅ 解決

### 症状

- README, HANDOFF, DESIGN_SPEC で記載が矛盾
- Phase III.2 が「完了」なのか「進行中」なのか不明
- どの文書が正しいのかわからない

### 原因

1. **更新漏れ**: 一部の文書だけ更新
2. **責務の曖昧さ**: どの文書に何を書くか不明確
3. **Git同期不足**: ローカル変更がpushされていない

### 対策

1. **文書責務の明確化**: DECISION_LOG, KNOWN_TRAPS 新設
2. **一括更新**: 関連文書を同時に更新
3. **Gitワークフロー徹底**: 変更したら即push

### 教訓

> **「文書は生き物。放置すると腐る」**

---

## TRAP-006: 「同意点即実行」の罠

**発見日:** 2026-01-19
**深刻度:** 🟡 Medium（LLM協業特有）
**状態:** ⚠️ 継続的注意

### 症状

- 複数のAI（Claude, Gemini, Copilot）が同意した内容を即実行
- 後から「実は見落としがあった」と判明

### 原因

- LLMは「同意」しやすい傾向がある
- 反論がないことは正しさの証明ではない
- 全員が同じ盲点を持っている可能性

### 対策

1. **「なぜ同意するのか」を問う**
2. **意図的に反論を求める**
3. **事実（データ、実験結果）で検証**
4. **Decision Log に記録し、後から検証可能に**

### 教訓

> **「同意は安心ではない。検証せよ」**

---

## テンプレート

新しい罠を記録する際は以下のフォーマットを使用：
```markdown
## TRAP-XXX: [罠の名前]

**発見日:** YYYY-MM-DD
**深刻度:** 🔴 Critical / 🟡 Medium / 🟢 Low
**状態:** ✅ 解決 / 🔄 対処中 / ⚠️ 継続的注意

### 症状
[どのような問題が発生したか]

### 原因
[なぜ発生したか]

### 対策
[どう解決したか / 解決するか]

### 教訓
> **「一言でまとめた教訓」**
```

---

*"Le symbole donne à penser."* — Paul Ricœur

## TRAP-007: 文書ベースの推測による実装状態の誤認

**発見日:** 2026-01-19
**深刻度:** 🟡 Medium
**状態:** ✅ 解決

### 症状

- ARCHITECTURE_OVERVIEW作成時、RayCast/Diffusion/Fusionを「将来構想（未実装）」と記載
- 実際にはソースコードに実装済み・有効化済みだった
- 文書（DESIGN_SPEC, HANDOFF等）に記載がなかったため、存在しないと判断

### 原因

1. **文書依存の調査**: LLMは文書を「真実のソース」として扱いがち
2. **ソースコード未確認**: 文書に書いてあることだけを信じた
3. **暗黙知の非文書化**: 開発者（山田さん）は知っていたが、LLMに伝える必要性を感じなかった

### 経緯

- 2025/1/14-15: Diffusion + RayCast + Fusion を実装（Phase III.1）
- 2025/1/17: Tromp-Taylor への方針転換、文書の焦点がそちらに移る
- 2026/1/19: ARCHITECTURE_OVERVIEW作成時に「未実装」と誤記
- 2026/1/19: ソースコード直接調査で実装済みと判明

### 対策

1. **ソースコード直接検査を必須化**: 文書だけでなく `grep` で実装確認
2. **「存在しない」と書く前に検証**: 特に複雑なコンポーネントについて
3. **実装ファイル一覧を文書に含める**: 何が存在するかを明示

### 教訓

> **「文書は不完全。ソースコードこそが真実のソース（Source of Truth）」**

---


## TRAP-008: 視点破綻（Perspective Collapse）

**発見日:** 2026-01-19
**深刻度:** 🔴 Critical
**状態:** ✅ 解決（DEC-008）

### 症状

- Loss が 5.9 で停滞し、相転移が起きない
- Win Rate が 0%（ランダムにすら勝てない）
- しかしパス連打ではなく、石は正常に配置されている
- 評価スクリプトは正常（Random vs Random で komi=0 なら約50%）

### 原因

学習時に盤面を常に「黒=+1, 白=-1」の絶対座標でモデルに渡していた。

白番のとき：
- Reward は winner * perspective で正しく変換されていた
- しかし Board は黒視点固定
- モデルは「自分の石が -1」という矛盾した状態で学習
- 結果、何も学習できず Loss が一様分布（5.88）付近で停滞

### 対策

perspective = 1.0 if idx % 2 == 0 else -1.0
current_board = current_board * perspective

これにより Board / Seq / Reward が整合する。

### 教訓

> **「Reward だけでなく、全ての入力が視点と整合しているか確認せよ」**

## TRAP-009: 盤面と履歴の視点不整合（Perspective Mismatch）

**発見日:** 2026-01-20
**深刻度:** 🔴 Critical
**状態:** ✅ 解決（DEC-009）

### 症状

- DEC-008（視点正規化）を適用したにもかかわらず Win Rate 0% が継続
- Loss(P) が 5.9 付近で停滞し、相転移が起きない
- Pass は 0.2% と正常（パス連打ではない）
- Value Loss もほぼ改善しない

### 原因

**「盤面は主観化したが、履歴は客観のまま」という認知的不整合**

| 入力 | 視点 | 問題 |
|------|------|------|
| 盤面（Board） | 主観 | DEC-008 で「自分=+1, 相手=-1」に正規化済み ✅ |
| 履歴（Sequence） | 客観 | 「誰が打ったか」の情報がない ❌ |

Mamba の入力設計を確認したところ：
```python
# model.py - MambaModel.forward
h = self.embedding(x)  # x は token ID（0〜362）のみ
```

seq には手番情報が一切含まれず、Mamba は「誰の手か」を識別できない状態だった。

**Copilot の表現:**
> 「視覚（boards）と記憶（seq）が別の世界線を見ている」

**Gemini の表現:**
> 「主語（誰が）も時制（いつ）も奪われた『単なる単語（座標）の羅列』を放り込んでいる」

### なぜ危険か

- TRAP-008（視点破綻）を修正しても、この問題が残っていると効果がない
- 盤面だけ主観化しても、履歴が客観のままでは整合性が取れない
- Policy Head が「誰の意志で打てばいいか」を判断できない
- Loss(P) が一様分布（5.88）付近で停滞する

### 対策

**DEC-009: Turn Embedding の導入**
```python
# MambaModel.__init__ 内
self.turn_emb = nn.Embedding(2, config.D_MODEL)  # 0=Self, 1=Other

# MambaModel.forward 内
h = self.embedding(seq)           # [B, T, D] (空間情報)
h = h + self.turn_emb(turn_seq)   # [B, T, D] (主観コンテキストの付与)
```

これにより：
- 各着手が「自分の手か相手の手か」を識別可能に
- 盤面（主観）と履歴（主観化）の整合性が確立
- vocab_size=363 を維持（DEC-002 との整合）
- Information Continuity を維持（Tessera 哲学との整合）

### TRAP-008 との関係

| TRAP | 問題 | 影響範囲 | 解決 |
|------|------|----------|------|
| TRAP-008 | 盤面が黒視点固定 | Board 入力 | DEC-008 |
| TRAP-009 | 履歴に手番情報なし | Sequence 入力 | DEC-009 |

TRAP-008 と TRAP-009 は**両方とも解決しないと Win Rate は改善しない**。

### 教訓

> **「視点の整合性は、全ての入力経路で確保せよ」**

盤面だけ、履歴だけ、ではなく、モデルに渡す**全ての入力**が同じ視点で整合している必要がある。

### 発見の経緯

1. DEC-008 適用後も Win Rate 0% → 「まだ何か漏れている」
2. Copilot が step() の視点変換漏れを指摘 → 修正
3. それでも Win Rate 0% → 「もっと深い問題がある」
4. Gemini が「seq に手番情報がない」と指摘
5. Copilot が「盤面は主観、履歴は客観」という構造的問題を言語化
6. Claude が Tessera 思想との相性を評価表で整理
7. 三者一致で Option B（Turn Embedding）を採用
